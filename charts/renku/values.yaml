## Default values for renku.
## This is a YAML-formatted file.
## Declare variables to be passed into your templates.

## Global variables
## Shared values/secrets
global:
  gitlab:
    ## Client secret, set this to a random string.
    ## To change this value after deploying, first generate a new secret using the Keycloak admin console
    ## then paste the generated secret here
    clientSecret: open_secret
    ## Name of the postgres database to be used by Gitlab
    postgresDatabase: gitlabhq_production
    ## Postgres user for the gitlab database
    postgresUser: gitlab
    ## Postgres password for the gitlab database
    postgresPassword: gitlab
    ## Sudo token for sudo API requests
    sudoToken: dummy-secret
    ## URL prefix for gitlab
    # urlPrefix: /

  keycloak:
    ## Name of the postgres database to be used by Keycloak
    postgresDatabase: keycloak
    ## Postgres user for the Keycloak database
    postgresUser: keycloak
    ## Postgres password for the Keycloak database
    postgresPassword: keycloak
  jupyterhub:
    ## Name of the postgres database to be used by jupyterhub
    postgresDatabase: jupyterhub
    ## Postgres user for the jupyterhub database
    postgresUser: jupyterhub
    ## Postgres password for the jupyterhub database
    postgresPassword: jupyterhub
  gateway:
    clientSecret: dummy-secret
  renku:
    ## Domain name for the deployed instance of renku
    domain: example.local
  ## Set to true if using https
  useHTTPS: false

## Ingress configuration
## See: https://kubernetes.io/docs/concepts/services-networking/ingress/
ingress:
  ## Enables the creation of an ingress
  enabled: false

  ## Annotations for the created ingress
  annotations:
    ## The ingress class
    kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
    nginx.ingress.kubernetes.io/proxy-body-size: '0' # Adjust to a reasonable value for production to avoid DOS attacks.

  ## Hosts for the ingress
  ## Should include at least the value from `global.renku.domain`
  hosts:
    - example.local

  ## TLS setting for the ingress
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - example.local

## Keycloak configuration
keycloak:
  ## Spawn a keycloak instance
  enabled: true

  keycloak:

    ## Keycloak admin user configuration
    username: admin
    password: admin

    extraInitContainers: |
      - name: theme-provider
        image: renku/keycloak-theme:v1.2
        imagePullPolicy: IfNotPresent
        command:
          - sh
        args:
          - -c
          - |
            echo "Copying theme..."
            cp -Rfv /renku_theme/* /theme
        volumeMounts:
          - name: theme
            mountPath: /theme

    extraVolumes: |
      - name: realm-secret
        secret:
          secretName: renku
          items:
          - key: renku-realm.json
            path: renku-realm.json
      - name: theme
        emptyDir: {}

    extraVolumeMounts: |
      - name: realm-secret
        mountPath: "/realm/"
        readOnly: true
      - name: theme
        mountPath: /opt/jboss/keycloak/themes/renku-theme

    extraArgs: -Dkeycloak.import=/realm/renku-realm.json

    persistence:

      # Disable deployment of the PostgreSQL chart
      deployPostgres: false

      # The database vendor. Can be either "postgres", "mysql", "mariadb", or "h2"
      dbVendor: postgres

      ## The following values only apply if "deployPostgres" is set to "false"
      dbName: keycloak
      # !!!
      ## This value is dependent on the Release name! (but helm charts don't allow templating values here.)
      # !!!
      dbHost: renku-postgresql
      dbPort: 5432 # 5432 is PostgreSQL's default port. For MySQL it would be 3306
      dbUser: keycloak

      # !!!
      ## This value is dependent on the Release name! (but helm charts don't allow templating values here.)
      # !!!
      existingSecret: renku
      existingSecretKey: keycloak-password

    ingress:
      enabled: false


postgresql:
  ## postgres image repository
  image: postgres
  ## postgres image version
  ## ref: https://hub.docker.com/r/library/postgres/tags/
  ##
  imageTag: '9.6'

  ## Specify a imagePullPolicy
  ## 'Always' if imageTag is 'latest', else set to 'IfNotPresent'
  ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
  ##
  # imagePullPolicy:

  ## Specify imagePullSecrets
  ## ref: https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod
  ##
  # imagePullSecrets: myregistrykey

  ## Create a database user
  ## Default: postgres
  postgresUser: postgres
  ## Default: random 10 character string
  postgresPassword: postgres

  ## Inject postgresPassword via a volume mount instead of environment variable
  # usePasswordFile: false

  ## Use Existing secret instead of creating one
  ## It must have a postgres-password key containing the desired password
  # existingSecret: 'secret'

  ## Create a database
  ## Default: the postgres user
  postgresDatabase: postgres

  ## Specify initdb arguments, e.g. --data-checksums
  ## ref: https://github.com/docker-library/docs/blob/master/postgres/content.md#postgres_initdb_args
  ## ref: https://www.postgresql.org/docs/current/static/app-initdb.html
  # postgresInitdbArgs:

  ## Use an alternate scheduler, e.g. "stork".
  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
  ##
  # schedulerName:

  ## Specify runtime config parameters as a dict, using camelCase, e.g.
  ## {"sharedBuffers": "500MB"}
  ## ref: https://www.postgresql.org/docs/current/static/runtime-config.html
  # postgresConfig:

  ## Persist data to a persistent volume
  persistence:
    enabled: true

    ## A manually managed Persistent Volume and Claim
    ## Requires persistence.enabled: true
    ## If defined, PVC must be created manually before volume will be bound
    # existingClaim:

    ## database data Persistent Volume Storage Class
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
    ##   GKE, AWS & OpenStack)
    ##
    # storageClass: "-"
    accessMode: ReadWriteOnce
    size: 8Gi
    subPath: postgresql-db
    mountPath: /var/lib/postgresql/data/pgdata

    # annotations: {}

  metrics:
    enabled: false
    image: wrouesnel/postgres_exporter
    imageTag: v0.1.1
    imagePullPolicy: IfNotPresent
    resources:
      requests:
        memory: 256Mi
        cpu: 100m
      ## Define additional custom metrics
      ## ref: https://github.com/wrouesnel/postgres_exporter#adding-new-metrics-via-a-config-file
      # customMetrics:
      #   pg_database:
      #     query: "SELECT d.datname AS name, CASE WHEN pg_catalog.has_database_privilege(d.datname, 'CONNECT') THEN pg_catalog.pg_database_size(d.datname) ELSE 0 END AS size FROM pg_catalog.pg_database d where datname not in ('template0', 'template1', 'postgres')"
      #     metrics:
      #       - name:
      #           usage: "LABEL"
      #           description: "Name of the database"
      #       - size_bytes:
      #           usage: "GAUGE"
      #           description: "Size of the database in bytes"

  ## Configure resource requests and limits
  ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
  ##
  resources:
    requests:
      memory: 256Mi
      cpu: 100m

  service:
    type: ClusterIP
    port: 5432
    externalIPs: []
    ## Manually set NodePort value
    ## Requires service.type: NodePort
    # nodePort:

  networkPolicy:
    ## Enable creation of NetworkPolicy resources.
    ##
    enabled: false

    ## The Policy model to apply. When set to false, only pods with the correct
    ## client label will have network access to the port PostgreSQL is listening
    ## on. When true, PostgreSQL will accept connections from any source
    ## (with the correct destination port).
    ##
    allowExternal: true

  ## Node labels and tolerations for pod assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#taints-and-tolerations-beta-feature
  nodeSelector: {}
  tolerations: []
  affinity: {}

  # Override default liveness & readiness probes
  probes:
    liveness:
      initialDelay: 60
      timeoutSeconds: 5
      failureThreshold: 6
    readiness:
      initialDelay: 5
      timeoutSeconds: 3
      periodSeconds: 5
  ## Annotations for the deployment and nodes.
  deploymentAnnotations: {}
  podAnnotations: {}

  ## Deployment pods replace strategy
  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy
  # strategy: {}


## PostgreSQL configuration
postgresqlOld:
  ## Password for the user postgres (database admin user)
  postgresPassword: postgres
  ## Postgres image
  # image:
  #   pullPolicy: IfNotPresent
  #   repository: postgres
  #   tag: 9.6

  ## Pod affinity for postgres deployment
  # affinity: {}
  ## Node selector for postgres deployment
  # nodeSelector: {}
  ## Pod tolerations for postgres deployment
  # tolerations: []

  ## Persistent Volume settings
  persistence:
    ## Set to false to disable the use of Persistent Volume
    ## The databases will be lost when the pod is terminated!
    # enabled: true

    ## A manually managed Persistent Volume and Claim
    ## Requires persistence.enabled: true
    ## If defined, PVC must be created manually before volume will be bound
    # existingClaim:

    ## database data Persistent Volume Storage Class
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
    ##   GKE, AWS & OpenStack)
    ##
    # storageClass:

    # accessMode: ReadWriteOnce
    # mountPath: /var/lib/postgresql/data/pgdata
    size: 8Gi
    # subPath: postgresql-db

  ## Metrics collection configuration
  # metrics:
  #   enabled: false
  #   image: wrouesnel/postgres_exporter
  #   imagePullPolicy: IfNotPresent
  #   imageTag: v0.1.1
  #   resources:
  #     requests:
  #       cpu: 100m
  #       memory: 256Mi

  ## Network policy
  # networkPolicy:
  #   allowExternal: true
  #   enabled: false

  ## Resource requests/limits for postgres
  # resources:
  #   requests:
  #     cpu: 100m
  #     memory: 256Mi

  ## Service configuration for PostgreSQL
  ## Modify service.type according to your setup
  # service:
  #   externalIPs: []
  #   port: 5432
  #   type: ClusterIP

## Gitlab configuration
gitlab:
  ## Spawn a gitlab instance
  enabled: true
  ## Password for the `root` user
  password: gitlabadmin

  ## Gitlab image
  # image:
  #   pullPolicy: IfNotPresent
  #   repository: gitlab/gitlab-ce
  #   tag: latest

  ## Pod affinity for Gitlab deployment
  # affinity: {}
  ## Node selector for Gitlab deployment
  # nodeSelector: {}
  ## Pod tolerations for Gitlab deployment
  # tolerations: []

  ## Resource requests/limits for Gitlab
  # resources: {}

  ## Registration token for gitlab runners (initial value, can be regenerated from gitlab admin ui)
  sharedRunnersRegistrationToken: 8dbf016f5b73d5608390183bbea9ce5fbed83a9dadefa719245ab93eb255cc29

  ## Set to true to make the user 'demo' a GitLab admin
  demoUserIsAdmin: false

  ## External port for git ssh protocol
  ## This setting affects the copy-paste repo git+ssh URL
  # sshPort: 22

  ## LFS objects settings
  ## Used to store git-lfs objects externally
  ## Note: bucket must exist before use, GitLab won't do it
  # lfsObjects:
      ## Set to true to enable remote LFS objects
      # enabled: false
      ## Bucket name
      # bucketName: lfs-objects
      ## Configuration, see: https://docs.gitlab.com/ce/workflow/lfs/lfs_administration.html
      # storage: |-
      #   {
      #     'provider' => 'AWS',
      #     'region' => 'eu-central-1',
      #     'aws_access_key_id' => '1ABCD2EFGHI34JKLM567N',
      #     'aws_secret_access_key' => 'abcdefhijklmnopQRSTUVwxyz0123456789ABCDE',
      #     # The below options configure an S3 compatible host instead of AWS
      #     'host' => 'localhost',
      #     'endpoint' => 'http://127.0.0.1:9000',
      #     'path_style' => true
      #   }

  ## Persistent Volume settings
  persistence:
    ## Set to false to disable the use of Persistent Volume
    ## The databases will be lost when the pod is terminated!
    # enabled: true

    ## A manually managed Persistent Volume and Claim
    ## Requires persistence.enabled: true
    ## If defined, PVC must be created manually before volume will be bound
    # existingClaim:

    ## database data Persistent Volume Storage Class
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
    ##   GKE, AWS & OpenStack)
    ##
    # storageClass:

    # accessMode: ReadWriteOnce
    size: 30Gi

    ## Mount points for the PV
    ## Setup according to the volumes declared in the Gitlab image
    # gitlab_data:
    #   subPath: data
    #   mountPath: /var/opt/gitlab
    # gitlab_config:
    #   subPath: config
    #   mountPath: /etc/gitlab
    # gitlab_logs:
    #   subPath: logs
    #   mountPath: /var/log/gitlab

  ## Service configuration for Gitlab
  ## Modify service.type according to your setup
  # service:
  #   port: 80
  #   type: ClusterIP

  ## Container image registry settings
  registry:
    ## Set to true to enable Gitlab registry
    enabled: false
    ## The URL to access the registry
    # externalUrl:
    ## Set `exposedAs` to "NodePort" when deploying on minikube
    ## Set `exposedAs` to "Ingress" to expose the registry on an alternate domain.
    # exposedAs: NodePort
    ## Storage driver configuration for the registry
    ## See: https://docs.gitlab.com/ee/administration/container_registry.html#container-registry-storage-driver
    # storage: |-
    #   {
    #     's3' => {
    #       'accesskey' => 's3-access-key',
    #       'secretkey' => 's3-secret-key-for-access-key',
    #       'bucket' => 'your-s3-bucket',
    #       'region' => 'your-s3-region'
    #     }
    #   }
    ## Registry ingress, when `exposedAs` is set to "Ingress"
    ## Uses conventional settings for ingress
    ## Find below an example of values
    # ingress:
    #   annotations:
    #     kubernetes.io/ingress.class: nginx
    #     kubernetes.io/tls-acme: "true"
    #     nginx.ingress.kubernetes.io/proxy-body-size: '0'
    #   hosts:
    #   - registry.example.com
    #   tls:
    #   - hosts:
    #     - registry.example.com
    #     secretName: registry-tls

## Redis configuration
## Redis is used by Gitlab
redis:

  cluster:
    enabled: false

  usePassword: false

  master:
    persistence:
      enabled: false

  networkPolicy:
    enabled: true
    allowExternal: false

## Configuration for the UI service
ui:
  #  welcomePage:
  #    text: "## Some markdown text here!"
  ## UI image
  # image:
  #   pullPolicy: Always
  #   repository: renku/renku-ui
  #   tag: latest

  ingress:
    enabled: false

  ## Pod affinity for UI deployment
  # affinity: {}
  ## Node selector for UI deployment
  # nodeSelector: {}
  ## Pod tolerations for UI deployment
  # tolerations: []

  ## Replica count
  # replicaCount: 1

  ## Service configuration for UI
  ## Modify service.type according to your setup
  # service:
  #   port: 80
  #   type: ClusterIP
  ## Set the GitLab URL
  # gitlabUrl: "http://gitlab.renku.build"
  ## Configure application ID from "{{ gitlabUrl }}/oauth/application"
  ## by setting redirect URL to "{{ baseUrl }}/login/redirect/gitlab"
  ## and set the application ID as the "gitlabClientId" chart value.
  # gitlabClientId: "renku-ui"
  ## Set the JupyterHub URL
  # jupyterhubUrl: "http://jupyterhub.renku.build"

## Configuration for the jupyterhub service
jupyterhub:
  rbac:
    enabled: true
  hub:
    image:
      name: renku/jupyterhub-k8s
      tag: '0.2.0-rc3'
    services:
      notebooks:
        url: http://renku-notebooks
        admin: true
        api_token: notebookstoken
    extraEnv:
      DEBUG: 1
      JUPYTERHUB_NOTEBOOK_DIR: /home/jovyan/work
      JUPYTERHUB_SPAWNER_CLASS: spawners.RenkuKubeSpawner
    extraConfig: |
      import os

      # Set the log level by value or name.
      c.JupyterHub.log_level = 'DEBUG'

      # Enable debug-logging of the single-user server
      c.Spawner.debug = True

      # JupyterHub uses GITLAB_HOST which is a misnomer -- we use GITLAB_URL
      # everywhere so set this mapping here
      os.environ['GITLAB_HOST'] = os.getenv('GITLAB_URL')

      #: Automatically begin the login process without showing the button.
      c.Authenticator.auto_login = True

      #: Enable named-servers
      c.JupyterHub.allow_named_servers = True

      #: Configure the notebook spawner.
      c.JupyterHub.spawner_class = os.getenv('JUPYTERHUB_SPAWNER_CLASS',
                                           'spawners.Spawner')

      c.RenkuKubeSpawner.pod_name_template = 'jupyter-{username}{servername}'

      #: Explicitly set notebook directory because we'll be mounting a host volume to
      #: it.  Most jupyter/docker-stacks *-notebook images run the Notebook server as
      #: user `jovyan`, and set the notebook directory to `/home/jovyan/work`.
      #: We follow the same convention.
      notebook_dir = os.getenv('JUPYTERHUB_NOTEBOOK_DIR', '/home/jovyan/work')
      c.Spawner.notebook_dir = notebook_dir

      #: For debugging arguments passed to spawned containers
      c.Spawner.debug = bool(os.getenv('DEBUG', False))

      # Increase pod initialization timeout to 15 minutes
      c.KubeSpawner.start_timeout = 60 * 15

      # prevent redirect to /hub if the server is taking slightly longer to start
      c.JupyterHub.tornado_settings = {
        'slow_spawn_timeout': 1
      }

  singleuser:
    image:
      name: renku/singleuser
      tag: '0.2.0-rc3'
    storage:
      type: none
    defaultUrl: /lab
  # FIXME: bug in prepuller makes helm hang in certain cases. Fixed in 0.7
  # so this should be removed eventually.
  # https://github.com/jupyterhub/zero-to-jupyterhub-k8s/issues/477
  prePuller:
    hook:
      enabled: false
  auth:
    type: gitlab
    gitlab:
      clientId: jupyterhub
      clientSecret: dummy-secret
      callbackUrl: '""' # Forces the default callback url
  proxy:
    service:
      type: ClusterIP
      nodePorts: {}
    https:
      enabled: false
  cull:
    enabled: true
    timeout: 86400
    every: 60
apispec:
  image:
    repository: renku/apispec
    tag: '0.2.0-rc3'

tests:
  image:
    repository: renku/tests
    tag: '0.2.0-rc3'

minio:
  ## Set to true to deploy a minio server, can be used as gateway too.
  enabled: false

## Configuration for the Gateway service
gateway:
  ingress:
    enabled: false
